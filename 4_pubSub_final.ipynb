{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_pubSub_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ws_n_2r8v1u-",
        "KprSvRYxwCs6",
        "N6tPyPsiwbkm"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarianaDuartee/ProjetoFinal/blob/main/4_pubSub_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws_n_2r8v1u-"
      },
      "source": [
        "### INSTALANDO DEPENDENCIAS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2yUfbpxHmMR"
      },
      "source": [
        "!pip install google-cloud-pubsub\n",
        "!pip install fsspec\n",
        "!pip install gcsfs\n",
        "!pip install apache-beam[interactive]\n",
        "!pip install apache_beam[gcp]\n",
        "!pip install google-cloud-bigquery"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYVBdRBLv8Os"
      },
      "source": [
        "### IMPORTANDO BIBLIOTECAS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEGAPAFZP8TJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1974a837-738f-40e6-9dd9-6eb3829631a9"
      },
      "source": [
        "import csv\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "\n",
        "import fsspec\n",
        "import gcsfs\n",
        "import pandas as pd\n",
        "\n",
        "import apache_beam as beam\n",
        "from apache_beam import window\n",
        "from apache_beam import coders\n",
        "from apache_beam.io.gcp.bigquery import parse_table_schema_from_json\n",
        "from apache_beam.io.gcp.internal.clients import bigquery\n",
        "from apache_beam.options.pipeline_options import GoogleCloudOptions\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "from apache_beam.options.pipeline_options import SetupOptions\n",
        "from apache_beam.options.pipeline_options import StandardOptions\n",
        "\n",
        "from google.cloud import pubsub_v1\n",
        "from google.cloud import storage\n",
        "from google.cloud import bigquery\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Configurando conta de serviço\n",
        "service_account_key = r\"/content/soulcode-projeto-final-4b88bea6e07a.json\"\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = service_account_key"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsL9GtpZzmZq"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KprSvRYxwCs6"
      },
      "source": [
        "### PUB AND SUB (PUBLICANDO E CONSUMINDO DADOS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7GsFGaVR9D_"
      },
      "source": [
        "Produtor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52f8-cY-IeaR"
      },
      "source": [
        "# Setando o tópico de entrada (ingestão)\n",
        "topico = 'projects/soulcode-projeto-final/topics/ingestor_dados'\n",
        "publisher = pubsub_v1.PublisherClient()\n",
        "\n",
        "entrada = r\"/content/2_temp_temp_pandas_total_pop_ano_uf.csv\"\n",
        "\n",
        "# Visualizando entrada dos dados\n",
        "with open(entrada, 'rb') as file:\n",
        "    for row in file:\n",
        "        print('Publicando no topico: ', topico)\n",
        "        publisher.publish(topico,row)\n",
        "        time.sleep(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8vIScqvR-8w"
      },
      "source": [
        "Consumidor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfZBtyqySAzq"
      },
      "source": [
        "# Função de ACK (Aceite)\n",
        "def monstrar_msg(mensagem):\n",
        "  print(('Mensagem: {}'.format(mensagem)))\n",
        "  mensagem.ack()\n",
        "\n",
        "# Setando a subscrição de saída\n",
        "subscription = 'projects/soulcode-projeto-final/subscriptions/consumidor_dados_violencia'\n",
        "subscriber = pubsub_v1.SubscriberClient()\n",
        "\n",
        "subscriber.subscribe(subscription,callback=monstrar_msg)\n",
        "\n",
        "while True:\n",
        "  time.sleep(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8wzeZmeP0WU"
      },
      "source": [
        "# PIPELINE BATCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMthvlL0wHyd"
      },
      "source": [
        "### PIPELINE LOCAL PARA GCS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5dfP6BR36BD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef48dd60-ae4f-426b-e3de-f64d17a67917"
      },
      "source": [
        "# Criando pipeline\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "# Modelo de Pipeline. Ingerindo arquivos locais\n",
        "\n",
        "path_file = r'/content/drive/MyDrive/Projeto Final/OcorrenciasUF.json'\n",
        "\n",
        "rows = (\n",
        "    p1\n",
        "    |'Extrair_Dados' >> beam.io.ReadFromText(path_file, skip_header_lines=0, coder=coders.StrUtf8Coder())\n",
        "    |'Ler_Elementos' >> beam.Map(lambda element: element)\n",
        "    # |'Separar_Elementos' >> beam.Map(lambda element: element.split(','))\n",
        "    |'Gravar_resultado' >> beam.io.WriteToText('gs://data_lake_ingest_data/1_input/converter/OcorrenciasUF', file_name_suffix='.json')\n",
        "   )\n",
        "\n",
        "p1.run()\n",
        "\n",
        "df_test = pd.read_json('gs://data_lake_ingest_data/1_input/converter/OcorrenciasUF-00000-of-00001.json')\n",
        "print(df_test)\n",
        "print(df_test.dtypes)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              UF                           Tipo Crime  ...       Mês Ocorrências\n",
            "0           Acre                              Estupro  ...   janeiro          39\n",
            "1           Acre                     Furto de veículo  ...   janeiro          55\n",
            "2           Acre                     Homicídio doloso  ...   janeiro          14\n",
            "3           Acre      Lesão corporal seguida de morte  ...   janeiro           0\n",
            "4           Acre       Roubo a instituição financeira  ...   janeiro           0\n",
            "...          ...                                  ...  ...       ...         ...\n",
            "18769  Tocantins       Roubo a instituição financeira  ...  dezembro           6\n",
            "18770  Tocantins                       Roubo de carga  ...  dezembro           1\n",
            "18771  Tocantins                     Roubo de veículo  ...  dezembro          55\n",
            "18772  Tocantins  Roubo seguido de morte (latrocínio)  ...  dezembro           2\n",
            "18773  Tocantins               Tentativa de homicídio  ...  dezembro          42\n",
            "\n",
            "[18774 rows x 5 columns]\n",
            "UF             object\n",
            "Tipo Crime     object\n",
            "Ano             int64\n",
            "Mês            object\n",
            "Ocorrências     int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6tPyPsiwbkm"
      },
      "source": [
        "### GCS PARA BIGQUERY (BATCH)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "UZjFWi3hPqRB",
        "outputId": "86d28d12-a128-42f3-fc6d-22754e26e06c"
      },
      "source": [
        "# CONTINUANDO PIPELINE \n",
        "def print_row(element):\n",
        "    return print(element)\n",
        "    \n",
        "pipeline_args=['--runner=DataflowRunner',\n",
        "               '--job_name=bq-load',\n",
        "               '--project=soulcode-projeto-final',\n",
        "               '--region=southamerica-east1',\n",
        "               '--temp_location=gs://data_lake_ingest_data/temp_process',\n",
        "               '--staging_location=gs://data_lake_ingest_data/temp_process',\n",
        "               '--template_location=gs://data_lake_ingest_data/4_templates/template_model_batch',\n",
        "               '-–save_main_session'\n",
        "               ]\n",
        "\n",
        "options = PipelineOptions(pipeline_args)\n",
        "p1 = beam.Pipeline(options=options)\n",
        "\n",
        "path_file = 'gs://data_lake_ingest_data/2_temp/temp_pandas_total_pop_ano_uf.csv'\n",
        "\n",
        "table_schema = {\n",
        "    \"fields\": [\n",
        "                {\"name\":\"UF\", \"type\":\"STRING\", \"mode\":\"NULLABLE\"},\n",
        "                {\"name\":\"populacao_estimada\", \"type\":\"FLOAT\", \"mode\":\"NULLABLE\"}, \n",
        "                {\"name\":\"Ano\", \"type\":\"INTEGER\", \"mode\":\"NULLABLE\"},\n",
        "            ]\n",
        "        }\n",
        "\n",
        "# https://medium.com/datamindedbe/how-to-build-a-cleaning-pipeline-with-bigquery-and-dataflow-on-gcp-3d2f288d4e1b\n",
        "# https://stackoverflow.com/questions/48741327/writing-nested-schema-to-bigquery-from-dataflow-python\n",
        "# https://stackoverflow.com/questions/53784829/how-to-get-table-schema-from-json-file-parse-table-schema-from-json\n",
        "# https://stackoverflow.com/questions/59217700/dataflow-apache-beam-cant-write-on-bigquery\n",
        "\n",
        "rows = (\n",
        "        p1 \n",
        "        \n",
        "        |'Extraindo_Dados' >> beam.io.ReadFromText(path_file, skip_header_lines=0)\n",
        "        # |'Separar_Elementos' >> beam.Map(lambda element: element.split(','))\n",
        "        |'Print' >> beam.Map(lambda element: print_row(element)).with_output_types(Transaction)\n",
        "        |'Gravar_Resultado' >> beam.io.gcp.bigquery.WriteToBigQuery(\n",
        "                                    table='TesteBeamApache',\n",
        "                                    dataset='Teste',\n",
        "                                    project='soulcode-projeto-final',\n",
        "                                    custom_gcs_temp_location='gs://data_lake_ingest_data/temp_process',\n",
        "                                    schema=table_schema,\n",
        "                                    write_disposition=bigquery.WriteDisposition.WRITE_APPEND,\n",
        "                                    create_disposition=bigquery.CreateDisposition.CREATE_IF_NEEDED)\n",
        "        )\n",
        "\n",
        "p1.run().wait_until_finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-–save_main_session=True']\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-–save_main_session=True']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'UNKNOWN'"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    }
  ]
}